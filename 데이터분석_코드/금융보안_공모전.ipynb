{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0d1cc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import fitz\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09af5e70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading punkt: <urlopen error [SSL:\n",
      "[nltk_data]     CERTIFICATE_VERIFY_FAILED] certificate verify failed:\n",
      "[nltk_data]     unable to get local issuer certificate (_ssl.c:1028)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b476826a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from 은행산업 관련 기본지식.pdf...\n",
      "Extracting from 대학생을위한실용금융(제4판)_금융감독원_ePDF(20240320).pdf...\n",
      "Extracting from 대학생이 꼭 알아야할 금융이야기.pdf...\n",
      "모든 PDF 텍스트 추출 완료 및 combined_text.txt 저장됨\n"
     ]
    }
   ],
   "source": [
    "def extract_text_from_pdf(file_path):\n",
    "    text = ''\n",
    "    with fitz.open(file_path) as pdf:\n",
    "        for page in pdf:  # pdf.pages가 아니라 pdf 자체를 반복\n",
    "            page_text = page.get_text()\n",
    "            if page_text:\n",
    "                text += page_text + '\\n'\n",
    "    return text\n",
    "\n",
    "def extract_texts_from_folder(folder_path):\n",
    "    all_text = ''\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith('.pdf'):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            print(f\"Extracting from {filename}...\")\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "            all_text += f\"=== Start of {filename} ===\\n\"\n",
    "            all_text += text + '\\n\\n'\n",
    "    return all_text\n",
    "\n",
    "folder_path = '/Users/eunsol/Documents/금융데이터'  # PDF들이 들어있는 폴더 경로\n",
    "full_text = extract_texts_from_folder(folder_path)\n",
    "\n",
    "# 결과를 텍스트 파일로 저장\n",
    "with open('combined_text.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(full_text)\n",
    "\n",
    "print(\"모든 PDF 텍스트 추출 완료 및 combined_text.txt 저장됨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1f4a5aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # 줄바꿈, 탭을 공백으로 변경\n",
    "    text = text.replace('\\n', ' ').replace('\\t', ' ')\n",
    "    # 여러 공백을 한 칸 공백으로 변경\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    # 특수문자 일부 제거 (필요에 따라 수정)\n",
    "    text = re.sub(r'[■◆●▲▼◀▶★]', '', text)\n",
    "    # 문장부호 앞뒤 공백 제거\n",
    "    text = re.sub(r'\\s*([,.?!])\\s*', r'\\1 ', text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def split_korean_sentences(text):\n",
    "    # 마침표, 느낌표, 물음표 뒤에 공백이 있거나 줄바꿈이 오는 곳에서 분리\n",
    "    sentences = re.split(r'(?<=[.!?])\\s+', text)\n",
    "    return [s.strip() for s in sentences if s.strip()]\n",
    "\n",
    "def preprocess_korean_sentences(sentences):\n",
    "    cleaned = []\n",
    "    for line in sentences:\n",
    "        line = line.strip()\n",
    "        if len(line) < 5:\n",
    "            if re.match(r'^[\\d\\s\\.\\,\\-\\–\\=\\+\\(\\)\\[\\]\\/\\\\·※▶▶\\•a-zA-Z가-힣]{1,4}$', line):\n",
    "                continue\n",
    "        if re.match(r'^(그림|표|참고|출처|그림\\s*\\d+|표\\s*\\d+)', line):\n",
    "            continue\n",
    "        cleaned.append(line)\n",
    "    return cleaned\n",
    "\n",
    "processed_text = clean_text(full_text)\n",
    "sentences = split_korean_sentences(processed_text)\n",
    "filtered = preprocess_korean_sentences(sentences)\n",
    "\n",
    "with open('processed_sentences.txt', 'w', encoding='utf-8') as f:\n",
    "    for s in filtered:\n",
    "        f.write(s + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76c850e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a1395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d1449",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
